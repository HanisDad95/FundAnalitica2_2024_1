{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "pd.set_option('display.max_columns',None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import randint\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import *\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGUE DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_parquet(\"C:/Users/jf95n/OneDrive/Desktop/KaggleCompetition/df_train.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANÁLISIS EXPLORATORIO DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = full_data.loc[:,full_data.columns[full_data.isna().sum() > 0]].isna().sum().plot(kind = 'barh')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Datos faltantes por variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in full_data.isna().sum(axis = 1).value_counts().items():\n",
    "    match i:\n",
    "        case 0: \n",
    "            print(f'En el dataset hay {j} observaciones sin datos nulos.')   \n",
    "        case _:\n",
    "            print(f'En el dataset hay {j} observaciones con datos nulos o faltantes en {i} de sus variables.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = full_data['Target'].value_counts(normalize = True).plot(kind = 'bar')\n",
    "labels = (full_data.Target.value_counts(normalize = True).sort_index()*100).round(1).astype('str') + '%' \n",
    "ax.tick_params(axis = 'x', rotation = 0)\n",
    "ax.set_title(\"Categorías variable dependiente, conjunto de prueba\")\n",
    "ax.set_yticks([])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, labels = labels)\n",
    "ax.set_title('Distribución de la variable respuesta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.groupby(['ESTADO_CIVIL','Target'])['GENERO'].count().plot(kind = 'bar')\n",
    "ax.tick_params(axis = 'x', rotation = 0)\n",
    "ax.set_title(\"Categorías variable dependiente, conjunto de prueba\")\n",
    "ax.set_title('Distribución de la variable respuesta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se define una función para obtener el índice de las variables categóricas, numéricas y variable objetivo\n",
    "def SepararNumCate(df : pd.DataFrame, target_variable : str):\n",
    "    '''Returns a triplet with column names (numerical, categorical, target)\n",
    "    '''\n",
    "    numerical = df.select_dtypes(include = 'number').columns.to_list()\n",
    "    date_time = df.select_dtypes(include = 'datetime').columns.to_list()\n",
    "    categorical = df.select_dtypes(include = 'object').columns.to_list()\n",
    "    numerical.remove(target_variable) ## REMOVES THE TARGET VARIABLE\n",
    "    target = df[target_variable].copy()\n",
    "    return numerical, date_time, categorical, target\n",
    "\n",
    "\n",
    "num_idx, date_time_idx, categ_idx, target_idx = SepararNumCate(full_data,'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.select_dtypes(include = 'datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.loc[:,num_idx].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTLIERS UNIVARIADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[full_data.isna().sum(axis = 1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_idx:\n",
    "    plt.figure()\n",
    "    plt.title(i)\n",
    "    plt.boxplot(train_set[i], vert = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTLIERS MULTIVARIADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = full_data.loc[:,['mes_6', 'mes_5', 'mes_4', 'mes_3', 'mes_2', 'mes_1',]].agg('sum', axis = 1), x = full_data['Target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.loc[:,['GENERO','Target']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.loc[full_data['GENERO']=='M',['GENERO','Target']].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINES DE FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AQUÍ VAN TODAS LAS VARIABLES NUEVAS QUE SE VAN A CREAR\n",
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Perform arbitary transformation\n",
    "        X['IMC'] = X['PESO']/X['TALLA'] ### HACER UNA MEJOR CONSTRUCCIÓN DE ESTA VARIABLE QUE TOME EN CUENTA LA EDAD\n",
    "        X['SumCosto'] = X.loc[:,['mes_6', 'mes_5', 'mes_4', 'mes_3', 'mes_2', 'mes_1',]].agg(sum, axis = 1) ### \n",
    "        X['EdadComplicacion'] = (((X['Fecha_cero'] - X['FECHA_NACIMIENTO']).dt.components.days)/365).astype(int)\n",
    "\n",
    "        \n",
    "        X.drop(labels = 'Fecha_cero', axis = 1, inplace = True) ## IMPORTANTE ESTE PASO PARA QUE NO VAYAMOS A DEJAR ESTA VARIABLE\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.groupby(['GENERO','Target']).apply(lambda x : x.sample(frac = 0.9, random_state = 123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(full_data,test_size=0.1,stratify = full_data[['Target','GENERO']], shuffle = True, random_state = 123) ## IMPORTANTE MIRAR POR CUALES VARIABLES SE DEBE ESTRATIFICAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPUTATION AND STANDARDIZATION PIPELINES =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipelines for standardization\n",
    "\n",
    "num_stand = Pipeline(steps = [\n",
    "    ('numScaler',StandardScaler())\n",
    "])\n",
    "\n",
    "categ_stand = Pipeline(steps = [\n",
    "    ('categStand',OneHotEncoder(handle_unkown = 'ignore'))\n",
    "])\n",
    "\n",
    "columnScaler = ColumnTransformer(transformers = \n",
    "    [('numScaler',num_stand,num_idx),\n",
    "     ('categStand', categ_stand, categ_idx)],\n",
    "     remainder = 'drop'\n",
    "    )\n",
    "\n",
    "### Pipelines for imputation\n",
    "\n",
    "num_imp = Pipeline(steps = [\n",
    "    ('numerical_imputer',SimpleImputer(strategy = 'median'))\n",
    "])\n",
    "\n",
    "cat_imp = Pipeline(steps = [\n",
    "    ('categorical_imputer',SimpleImputer(strategy = 'most_frequent'))\n",
    "])\n",
    "\n",
    "columnImputer = ColumnTransformer(transformers = \n",
    "    [('NumericalImputer',num_imp,num_idx),\n",
    "     ('CategoricalImputer',cat_imp, categ_idx)\n",
    "\n",
    "    ],\n",
    "remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC(kernel, gamma, C, degree, coef0, tol):\n",
    "    kernel = int(kernel) ## (0,3)\n",
    "    n_jobs = -3 ## to use all but 2 cores.\n",
    "    kernels = ['linear','polynomial','rbf','sigmoid']\n",
    "    # match kernel:\n",
    "    #     case 2:\n",
    "    #         # use gamma : must be non-negative\n",
    "    #     case _:\n",
    "    #         # dont use gamma\n",
    "    classificator = SVC(C = C, kernel = kernels[kernel], class_weight = )\n",
    "    return -np.median(cross_val_score(classificator, x_train, y_train, n_jobs = n_jobs, cv = 5, scoring = 'f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0cba59e8686724c8b06d06e1b035ecd6727a6f1ef058d75f8ca5298c8c61292"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
